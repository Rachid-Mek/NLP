{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "42kllXv27FAM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.training.example import Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b7X0aVj7FAS"
      },
      "source": [
        "<h1> HOMEWORK </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vhO8GN7FAV"
      },
      "source": [
        "### PART1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAmB6VHC7FAV"
      },
      "source": [
        "# NNS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieoD6lhm7FAW"
      },
      "source": [
        "# Utilisation de fonction is_plural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUWefKo87FAW",
        "outputId": "cb3c4c0a-604d-4e86-c55f-ad52b30e397d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parks : NNS\n",
            "dogs : NNS\n",
            "adults : NNS\n",
            "picnics : NNS\n",
            "trees : NNS\n",
            "flowers : NNS\n",
            "gardens : NNS\n",
            "colors : NNS\n",
            "bees : NNS\n",
            "butterflies : NNS\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "def is_plural_noun(token):\n",
        "    # Load the spaCy model\n",
        "    if token.pos_ in [ \"PROPN\", \"VERB\", \"ADJ\", \"ADV\" , \"ADP\", \"AUX\", \"CONJ\", \"DET\", \"INTJ\", \"NUM\", \"PART\", \"PRON\", \"SCONJ\", \"SYM\", \"X\" ]:\n",
        "        return False\n",
        "    # Check if token ends with 's' and is not a single 's'\n",
        "    if token.text.endswith('s') and len(token.text) > 1:\n",
        "        # Check if the token is not a known exception (e.g., \"is\")\n",
        "        if token.text.lower() not in [\"is\", \"was\", \"has\", \"does\" , \"always\"] :\n",
        "            # Check if the token is not a possessive (e.g., \"John's\")\n",
        "            if not (token.text.endswith(\"'s\") or token.text.endswith(\"s'\")):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# Define a custom pipeline component for the POS tagger\n",
        "@nlp.component(\"custom_pos_tagger\")\n",
        "def custom_pos_tagger(doc):\n",
        "    for token in doc:\n",
        "        if is_plural_noun(token):\n",
        "            token.tag_ = \"NNS\"  # overwrite the token tag\n",
        "    return doc\n",
        "\n",
        "# Add the custom component to the pipeline\n",
        "nlp.add_pipe(\"custom_pos_tagger\") # add last to the pipeline\n",
        "\n",
        "\n",
        "\n",
        "# Prepare a training dataset with annotated POS tags\n",
        "training_data = [\n",
        "    (\"Cats are interesting animals.\", {\"tags\": [\"NNS\", \"VBP\", \"JJ\", \"NNS\", \".\"]}),\n",
        "    (\"Dogs and cats are friends.\", {\"tags\": [\"NNS\", \"CC\", \"NNS\", \"VBP\", \"NNS\", \".\"]}),\n",
        "    (\"Cats are from Venus.\", {\"tags\": [\"NNS\", \"VBP\", \"IN\", \"NNP\", \".\"]}),\n",
        "    (\"Dogs are from Mars.\", {\"tags\": [\"NNS\", \"VBP\", \"IN\", \"NNP\", \".\"]}),\n",
        "    (\"I have three dogs.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NNS\", \".\"]}),\n",
        "    (\"I have five cars.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NNS\", \".\"]}),\n",
        "    (\"I have ten cats and a dog.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NNS\", \"CC\", \"DT\", \"NN\", \".\"]}),\n",
        "    (\"My cat's toys are green.\", {\"tags\": [\"PRP$\", \"NN\", \"POS\", \"NNS\", \"VBZ\", \"JJ\", \".\"]}),\n",
        "    (\"I thought dogs' toys were green.\", {\"tags\": [\"PRP\", \"VBD\", \"NNS\", \"POS\", \"NNS\", \"VBD\", \"JJ\", \".\"]}),\n",
        "]\n",
        "# Train the model\n",
        "optimizer = nlp.begin_training()\n",
        "losses = {}\n",
        "for text, annotations in training_data:\n",
        "    example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "    nlp.update([example] ,  sgd=optimizer,drop=0.35, losses=losses)\n",
        "\n",
        "# Test the custom POS tagger\n",
        "doc = nlp(\"The city's parks are always bustling with people and their dogs. Children run and play, while adults enjoy picnics under the trees. The flowers in the gardens bloom in many colors, attracting bees and butterflies. It's a peaceful and lively place for everyone to relax and unwind\")\n",
        "\n",
        "for token in doc:\n",
        "    if token.tag_ == \"NNS\":\n",
        "        print(token.text, \":\", token.tag_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVZioKiH7FAZ"
      },
      "source": [
        "# 2 eme methode :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S7qxTc47FAa"
      },
      "source": [
        "<h3>  Utilisation des regex  </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dA_Ud6n7FAa",
        "outputId": "5d814286-2995-40d5-a6f7-267cd998714d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vendors : NNS\n",
            "fruits : NNS\n",
            "vegetables : NNS\n",
            "crafts : NNS\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from spacy.training.example import Example\n",
        "\n",
        "# Initialize a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Define a custom pipeline component for the POS tagger\n",
        "@nlp.component(\"custom_pos_tagger\")\n",
        "def custom_pos_tagger(doc):\n",
        "    for token in doc:\n",
        "        # Check if the token matches the plural noun pattern\n",
        "        if re.match(r'\\b\\w+s\\b', token.text) and token.text.lower() not in [\"is\", \"was\", \"has\", \"does\" , \"always\" , \"various\" ]:\n",
        "            token.tag_ = \"NNS\"  # overwrite the token tag\n",
        "    return doc\n",
        "\n",
        "# Add the custom component to the pipeline\n",
        "nlp.add_pipe(\"custom_pos_tagger\")\n",
        "\n",
        "# Prepare a training dataset with annotated POS tags\n",
        "training_data = [\n",
        "    (\"Cats are interesting animals.\", {\"tags\": [\"NNS\", \"VBP\", \"JJ\", \"NNS\", \".\"]}),\n",
        "    (\"Dogs and cats are friends.\", {\"tags\": [\"NNS\", \"CC\", \"NNS\", \"VBP\", \"NNS\", \".\"]}),\n",
        "    (\"Cats are from Venus.\", {\"tags\": [\"NNS\", \"VBP\", \"IN\", \"NNP\", \".\"]}),\n",
        "    (\"Dogs are from Mars.\", {\"tags\": [\"NNS\", \"VBP\", \"IN\", \"NNP\", \".\"]}),\n",
        "    (\"I have three dogs.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NNS\", \".\"]}),\n",
        "    (\"I have five cars.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NNS\", \".\"]}),\n",
        "    (\"I have a cat and a dog.\", {\"tags\": [\"PRP\", \"VBP\", \"DT\", \"NN\", \"CC\", \"DT\", \"NN\", \".\"]}),\n",
        "    (\"My cat's toy is green.\", {\"tags\": [\"PRP$\", \"NN\", \"POS\", \"NN\", \"VBZ\", \"JJ\", \".\"]}),\n",
        "    (\"I thought dogs' toys were green.\", {\"tags\": [\"PRP\", \"VBD\", \"NNS\", \"POS\", \"NNS\", \"VBD\", \"JJ\", \".\"]}),\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "optimizer = nlp.begin_training()\n",
        "losses = {}\n",
        "for text, annotations in training_data:\n",
        "    example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "    nlp.update([example], sgd=optimizer, drop=0.35, losses=losses)\n",
        "\n",
        "# Test the custom POS tagger\n",
        "doc = nlp(\"The bustling market was filled with vendors selling a colorful array of fruits, vegetables, and handmade crafts\")\n",
        "for token in doc:\n",
        "    if token.tag_ == \"NNS\":\n",
        "        print(token.text, \":\", token.tag_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSo_7IaS7FAb"
      },
      "source": [
        "# Methode : utilisation de corpus treebank for the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaKH0gjF7FAc",
        "outputId": "5f3b0614-fe09-467d-d2d2-b24daf51c533"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to\n",
            "[nltk_data]     C:\\Users\\rachi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package brown to\n",
            "[nltk_data]     C:\\Users\\rachi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package conll2000 to\n",
            "[nltk_data]     C:\\Users\\rachi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to\n",
            "[nltk_data]     C:\\Users\\rachi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "from nltk.corpus import treebank\n",
        "from nltk.corpus import conll2000\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('brown')\n",
        "nltk.download('conll2000')\n",
        "\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exok6WBi7FAd",
        "outputId": "4584fbf8-8674-4363-be36-a4405a31a51d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')]\n",
            "[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]\n",
            "[('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')]\n",
            "[('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')]\n",
            "[('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]\n",
            "[('Lorillard', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('the', 'DET'), ('unit', 'NOUN'), ('of', 'ADP'), ('New', 'ADJ'), ('York-based', 'ADJ'), ('Loews', 'NOUN'), ('Corp.', 'NOUN'), ('that', 'DET'), ('*T*-2', 'X'), ('makes', 'VERB'), ('Kent', 'NOUN'), ('cigarettes', 'NOUN'), (',', '.'), ('stopped', 'VERB'), ('using', 'VERB'), ('crocidolite', 'NOUN'), ('in', 'ADP'), ('its', 'PRON'), ('Micronite', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('in', 'ADP'), ('1956', 'NUM'), ('.', '.')]\n",
            "[('Although', 'ADP'), ('preliminary', 'ADJ'), ('findings', 'NOUN'), ('were', 'VERB'), ('reported', 'VERB'), ('*-2', 'X'), ('more', 'ADV'), ('than', 'ADP'), ('a', 'DET'), ('year', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('the', 'DET'), ('latest', 'ADJ'), ('results', 'NOUN'), ('appear', 'VERB'), ('in', 'ADP'), ('today', 'NOUN'), (\"'s\", 'PRT'), ('New', 'NOUN'), ('England', 'NOUN'), ('Journal', 'NOUN'), ('of', 'ADP'), ('Medicine', 'NOUN'), (',', '.'), ('a', 'DET'), ('forum', 'NOUN'), ('likely', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('bring', 'VERB'), ('new', 'ADJ'), ('attention', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('problem', 'NOUN'), ('.', '.')]\n",
            "[('A', 'DET'), ('Lorillard', 'NOUN'), ('spokewoman', 'NOUN'), ('said', 'VERB'), (',', '.'), ('``', '.'), ('This', 'DET'), ('is', 'VERB'), ('an', 'DET'), ('old', 'ADJ'), ('story', 'NOUN'), ('.', '.')]\n",
            "[('We', 'PRON'), (\"'re\", 'VERB'), ('talking', 'VERB'), ('about', 'ADP'), ('years', 'NOUN'), ('ago', 'ADP'), ('before', 'ADP'), ('anyone', 'NOUN'), ('heard', 'VERB'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('having', 'VERB'), ('any', 'DET'), ('questionable', 'ADJ'), ('properties', 'NOUN'), ('.', '.')]\n",
            "[('There', 'DET'), ('is', 'VERB'), ('no', 'DET'), ('asbestos', 'NOUN'), ('in', 'ADP'), ('our', 'PRON'), ('products', 'NOUN'), ('now', 'ADV'), ('.', '.'), (\"''\", '.')]\n"
          ]
        }
      ],
      "source": [
        "# load POS tagged corpora from NLTK\n",
        "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
        "brown_corpus = brown.tagged_sents(tagset='universal')\n",
        "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
        "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus\n",
        "import nltk\n",
        "\n",
        "# print first two sentences of the tagged_sentences corpus\n",
        "for sent in tagged_sentences[:10]:\n",
        "    print(sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUq71cbx7FAd",
        "outputId": "177d308a-58b5-4912-b0e2-e0889f9012fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input sequence: ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "Output sequence: ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
          ]
        }
      ],
      "source": [
        "X = [] # store input sequence\n",
        "Y = [] # store output sequence\n",
        "\n",
        "for sentence in tagged_sentences:\n",
        "    X_sentence = []\n",
        "    Y_sentence = []\n",
        "    for entity in sentence:\n",
        "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
        "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
        "\n",
        "    X.append(X_sentence)\n",
        "    Y.append(Y_sentence)\n",
        "\n",
        "# Print the first training sample\n",
        "print('Input sequence:', str(X[0]))\n",
        "print('Output sequence:', str(Y[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ALVKPW37FAe"
      },
      "outputs": [],
      "source": [
        "def adjust_tags(tags, sentence):\n",
        "    # Split the sentence into words\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Check if the number of words and tags differ by one\n",
        "    if len(words) == len(tags):\n",
        "        return tags\n",
        "    elif len(words) == len(tags) - 1:\n",
        "        # If there is one less tag, duplicate the last tag to match the number of words\n",
        "        adjusted_tags = tags + [tags[-1]]\n",
        "        return adjusted_tags\n",
        "    else:\n",
        "        raise ValueError(\"Number of words and tags do not match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5oQzdQE7FAf",
        "outputId": "672f526d-b264-4cc8-ce62-73fd464f3b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parks : NNS\n",
            "dogs : NNS\n",
            "adults : NNS\n",
            "picnics : NNS\n",
            "trees : NNS\n",
            "flowers : NNS\n",
            "gardens : NNS\n",
            "colors : NNS\n",
            "bees : NNS\n",
            "butterflies : NNS\n"
          ]
        }
      ],
      "source": [
        "# Combine elements of X and Y into a single list\n",
        "training_data = []\n",
        "for i in range(len(X)):\n",
        "    sentence = ' '.join(X[i])\n",
        "    tags = Y[i]\n",
        "    if len(sentence.split()) == len(tags):\n",
        "        example = (sentence, {\"tags\": tags})\n",
        "        training_data.append(example)\n",
        "    else:\n",
        "        tags = adjust_tags(tags, sentence)\n",
        "        example = (sentence, {\"tags\": tags})\n",
        "        training_data.append(example)\n",
        "\n",
        "# Train the model\n",
        "optimizer = nlp.begin_training()\n",
        "losses = {}\n",
        "for text, annotations in training_data:\n",
        "    doc = nlp.make_doc(text)\n",
        "    if len(doc) == len(annotations[\"tags\"]):\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "        nlp.update([example], sgd=optimizer, drop=0.35, losses=losses)\n",
        "\n",
        "\n",
        "# Test the trained model\n",
        "doc = nlp(\"The city's parks are always bustling with people and their dogs. Children run and play, while adults enjoy picnics under the trees. The flowers in the gardens bloom in many colors, attracting bees and butterflies. It's a peaceful and lively place for everyone to relax and unwind\")\n",
        "for token in doc:\n",
        "    if token.tag_ == \"NNS\":\n",
        "        print(token.text, \":\", token.tag_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJH4ej7U7FAh"
      },
      "source": [
        "<h2> PART2  </h2>\n",
        "Train a ner tagger to recognize a new entity label called “COLOR”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FOdeICUl7FAx"
      },
      "outputs": [],
      "source": [
        "from spacy.training.example import offsets_to_biluo_tags\n",
        "import random\n",
        "# to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Create a spaCy model with the \"ner\" component\n",
        "nlp = spacy.blank(\"en\")\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "# Add the new entity label \"COLOR\" to the NER model\n",
        "ner.add_label(\"COLOR\")\n",
        "\n",
        "TRAIN_DATA = [\n",
        "    (\"The sky is blue.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "    (\"The ocean is deep blue.\", {\"entities\": [(20, 24, \"COLOR\")]}),\n",
        "    (\"His favorite color is purple.\", {\"entities\": [(24, 30, \"COLOR\")]}),\n",
        "    (\"The ripe apple is red.\", {\"entities\": [(17, 20, \"COLOR\")]}),\n",
        "    (\"The card is red.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "\n",
        "    (\"The leaves turned golden.\", {\"entities\": [(18, 24, \"COLOR\")]}),\n",
        "    (\"The sky at sunset is orange.\", {\"entities\": [(20, 26, \"COLOR\")]}),\n",
        "    (\"The flag is red, white, and blue.\", {\"entities\": [(11, 14, \"COLOR\"), (17, 22, \"COLOR\"), (29, 33, \"COLOR\")]}),\n",
        "    (\"The walls are green.\", {\"entities\": [(14, 19, \"COLOR\")]}),\n",
        "    (\"The flowers are pink.\", {\"entities\": [(17, 21, \"COLOR\")]}),\n",
        "    (\"The book has a brown cover.\", {\"entities\": [(17, 22, \"COLOR\")]}),\n",
        "    (\"The car is silver.\", {\"entities\": [(12, 18, \"COLOR\")]}),\n",
        "    (\"The shirt is black.\", {\"entities\": [(14, 19, \"COLOR\")]}),\n",
        "    (\"The clouds are gray.\", {\"entities\": [(16, 20, \"COLOR\")]}),\n",
        "    (\"The banana is yellow.\", {\"entities\": [(14, 20, \"COLOR\")]}),\n",
        "    (\"The sun is yellow.\", {\"entities\": [(11, 17, \"COLOR\")]}),\n",
        "\n",
        "\n",
        "    (\"The grapes are purple.\", {\"entities\": [(15, 21, \"COLOR\")]}),\n",
        "    (\"The door is white.\", {\"entities\": [(13, 18, \"COLOR\")]}),\n",
        "    (\"The sky at dawn is pink.\", {\"entities\": [(18, 22, \"COLOR\")]}),\n",
        "\n",
        "    (\"The sky at dusk is pink.\", {\"entities\": [(18, 22, \"COLOR\")]}),\n",
        "    (\"The sky at midnight is black.\", {\"entities\": [(22, 27, \"COLOR\")]}),\n",
        "    (\"The sky at noon is blue.\", {\"entities\": [(18, 22, \"COLOR\")]}),\n",
        "    (\"The sky is blue and sometimes has clouds.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "    (\"The sky is blue and the sun is bright.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "    (\"The sky is pink and clear.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "    (\"The sky is blue and cloudless.\", {\"entities\": [(11, 15, \"COLOR\")]}),\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "adjusted_train_data = []\n",
        "for text, entities in TRAIN_DATA:\n",
        "    doc = nlp.make_doc(text)\n",
        "    biluo_tags = offsets_to_biluo_tags(doc, entities.get(\"entities\"))\n",
        "\n",
        "    corrected_entities = []\n",
        "    for entity, tag in zip(entities.get(\"entities\"), biluo_tags):\n",
        "        if tag != 'U':  # Ignore single-character entities that couldn't be aligned\n",
        "            start, end, label = entity\n",
        "            adjusted_start = text.find(text[start:end])\n",
        "            adjusted_end = adjusted_start + len(text[start:end])\n",
        "            corrected_entities.append((adjusted_start, adjusted_end, label))\n",
        "\n",
        "    adjusted_train_data.append((text, {\"entities\": corrected_entities}))\n",
        "TRAIN_DATA = adjusted_train_data\n",
        "\n",
        "optimizer = nlp.begin_training()\n",
        "# Start the training loop\n",
        "for _ in range(20):  # Number of epochs\n",
        "    # Shuffle the training data\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "        nlp.update([example], drop=0.2) # Decrease dropout rate to 20%\n",
        "\n",
        "# Save the model\n",
        "nlp.to_disk(\"custom_ner_model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow3MalvG7FAy"
      },
      "source": [
        "# Test the ner tagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "UZjLiejT7FAz",
        "outputId": "64adde39-9f92-4b3c-870e-bb9e6d8eba21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>RECOGNIZED COLORS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue</td>\n",
              "      <td>'blue'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sunflower is yellow</td>\n",
              "      <td>'yellow'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His favorite color is purple</td>\n",
              "      <td>'purple'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The leaves turned golden</td>\n",
              "      <td>'golden'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The flag is red, white, and blue</td>\n",
              "      <td>'white', 'blue'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The walls are green and the flowers are pink</td>\n",
              "      <td>'green', 'pink'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The car is silver and the shirt is black</td>\n",
              "      <td>'silver'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The clouds are gray and the banana is yellow</td>\n",
              "      <td>'gray', 'yellow'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The grapes are purple and the door is white</td>\n",
              "      <td>'purple', 'white'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The sky at dawn is pink</td>\n",
              "      <td>'pink'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       SENTENCE  RECOGNIZED COLORS\n",
              "0                               The sky is blue             'blue'\n",
              "1                       The sunflower is yellow           'yellow'\n",
              "2                  His favorite color is purple           'purple'\n",
              "3                      The leaves turned golden           'golden'\n",
              "4              The flag is red, white, and blue    'white', 'blue'\n",
              "5  The walls are green and the flowers are pink    'green', 'pink'\n",
              "6      The car is silver and the shirt is black           'silver'\n",
              "7  The clouds are gray and the banana is yellow   'gray', 'yellow'\n",
              "8   The grapes are purple and the door is white  'purple', 'white'\n",
              "9                       The sky at dawn is pink             'pink'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Load the custom NER model\n",
        "nlp = spacy.load(\"custom_ner_model\")\n",
        "\n",
        "# Test sentences\n",
        "test_sentences = [\n",
        "    \"The sky is blue\",\n",
        "    \"The sunflower is yellow\",\n",
        "    \"His favorite color is purple\",\n",
        "    \"The leaves turned golden\",\n",
        "    \"The flag is red, white, and blue\",\n",
        "    \"The walls are green and the flowers are pink\",\n",
        "    \"The car is silver and the shirt is black\",\n",
        "    \"The clouds are gray and the banana is yellow\",\n",
        "    \"The grapes are purple and the door is white\",\n",
        "    \"The sky at dawn is pink\",\n",
        "\n",
        "]\n",
        "\n",
        "# Process each sentence and print recognized entities\n",
        "for sentence in test_sentences:\n",
        "    doc = nlp(sentence)\n",
        "    # print(\"Entities in '{}':\".format(sentence))\n",
        "    for ent in doc.ents:\n",
        "        # print(ent.text, ent.label_)\n",
        "        pass\n",
        "    # print()\n",
        "\n",
        "# create a dataframe to store the results sentence and entities\n",
        "df = pd.DataFrame(columns=['SENTENCE','RECOGNIZED COLORS'])\n",
        "# Process each sentence and print recognized entities\n",
        "for sentence in test_sentences:\n",
        "    doc = nlp(sentence)\n",
        "    # print(\"Entities in '{}':\".format(sentence))\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append(ent.text)\n",
        "        # print(ent.text, ent.label_)\n",
        "    # remove the bracets\n",
        "    entities = str(entities).replace('[','').replace(']','')\n",
        "    new_row = {'SENTENCE': sentence, 'RECOGNIZED COLORS': entities}\n",
        "\n",
        "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-kULOjF7FA0"
      },
      "source": [
        "# LRIA & USTHB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lfJAFdX7FA0",
        "outputId": "b7ac0a8b-04a3-4436-8472-430f783b1ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entities [('USTHB', 'ORG'), ('LRIA', 'ORG')]\n",
            "USTHB ORG\n",
            "LRIA ORG\n"
          ]
        }
      ],
      "source": [
        "# corpus =  open(\"USTHB.txt\").read()\n",
        "# corpus= nlp(corpus)\n",
        "# Initialize spacy with a blank English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Define a custom pipeline component for entity recognition\n",
        "@nlp.component(\"custom_entity_recognition\")\n",
        "def custom_entity_recognition(doc):\n",
        "    # Define entities and labels\n",
        "    entities = [(\"USTHB\", \"ORG\"), (\"LRIA\", \"ORG\")]\n",
        "\n",
        "    # Iterate over entities and add them to the doc\n",
        "    for entity, label in entities:\n",
        "        start = doc.text.find(entity)\n",
        "        if start != -1: # found\n",
        "            end = start + len(entity) # get end character index of entity\n",
        "            span = doc.char_span(start, end, label=label) # create Span for entity\n",
        "            if span is not None: # entity is not overlapping\n",
        "                doc.ents = list(doc.ents) + [span] # add span to doc.ents\n",
        "    return doc\n",
        "\n",
        "# Add the custom component to the pipeline\n",
        "nlp.add_pipe(\"custom_entity_recognition\") # add last to the pipeline\n",
        "\n",
        "# Assuming you have a custom corpus for USTHB and LRIA as ORG entities\n",
        "custom_corpus = [\n",
        "    (\"USTHB is a university in Algeria\", {}),\n",
        "    (\"LRIA is a research institute\", {}),\n",
        "    (\"USTHB and LRIA are located in Algiers\", {}),\n",
        "    (\"USTHB and LRIA are in the same campus\", {}),\n",
        "    (\"USTHB and LRIA are in the same city\", {}),\n",
        "    (\"USTHB and LRIA are in the same country\", {}),\n",
        "    (\"USTHB and LRIA are in the same continent\", {}),\n",
        "    (\"USTHB and LRIA are in the same planet\", {}),\n",
        "    (\"USTHB and LRIA are in the same solar system\", {}),\n",
        "    (\"USTHB and LRIA are in the same galaxy\", {}),\n",
        "    (\"USTHB and LRIA are in the same universe\", {}),\n",
        "    (\"USTHB and LRIA are in the same multiverse\", {}),\n",
        "    (\"USTHB and LRIA are in the same megaverse\", {}),\n",
        "    (\"USTHB and LRIA are in the same omniverse\", {}),\n",
        "]\n",
        "\n",
        "optimizer = nlp.begin_training()\n",
        "# Prepare training data\n",
        "for text, annotations in custom_corpus: # iterate over the data\n",
        "    doc = nlp.make_doc(text) # create a Doc object from the text\n",
        "    example = Example.from_dict(doc, annotations) # create Example object from the annotations\n",
        "    nlp.update([example], drop=0.5 , sgd=optimizer) # update the model\n",
        "\n",
        "# Test the trained model\n",
        "doc = nlp(\"USTHB and LRIA are in the same city\")\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
